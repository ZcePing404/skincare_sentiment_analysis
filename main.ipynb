{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQNuIWijqojPezlzl7lC4n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZcePing404/skincare_sentiment_analysis/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "GjwFRqlCIVw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def handle_duplicate(df) -> pd.DataFrame:\n",
        "  return df\n",
        "\n",
        "\n",
        "def handle_missing(df) -> pd.DataFrame:\n",
        "  return df\n",
        "\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "  # Lowercase\n",
        "  # Handles punctuation, numbers, symbols, emoji\n",
        "\n",
        "  text = str(TextBlob(text).correct()) # Correct misspelling words\n",
        "  return text"
      ],
      "metadata": {
        "id": "slNtjjpEIhe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocessing**"
      ],
      "metadata": {
        "id": "bOTuOTxNIVAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> list[str]:\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "def remove_stopwords(tokens: list[str]) -> list[str]:\n",
        "  return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "\n",
        "def lemmatize_tokens(tokens: list[str]) -> list[str]:\n",
        "  return []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWdNyLLqF1v8",
        "outputId": "e5c92661-a929-41b4-998b-c23d3716dcea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LDA - Extracting Aspects**"
      ],
      "metadata": {
        "id": "cgXQWr7EJlER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0bXtUfO0Fuk3"
      },
      "outputs": [],
      "source": [
        "def train_lda_model(tokens: list[str]):\n",
        "    return 0\n",
        "\n",
        "\n",
        "def extract_keyword(lda_model):\n",
        "    return 0\n",
        "\n",
        "\n",
        "# Summarize positive/neutral/negative reasons for product recommendation.\n",
        "def summarize_aspects(topics, sentiments, topic_keywords):\n",
        "    return 0\n",
        "\n",
        "\n",
        "# OPTIONAL\n",
        "# Convert topic keywords into hashtag-like summary terms.\n",
        "def generate_hashtags(topic_keywords):\n",
        "    return 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**"
      ],
      "metadata": {
        "id": "u1MBzpMlMRl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model"
      ],
      "metadata": {
        "id": "z1n5QRoQP-Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "\n",
        "class LIMWEIHEModel(nn.Module):\n",
        "  def init(self):\n",
        "    super().init()\n",
        "\n",
        "  def forward(self):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "L4xQ44aHQLZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "qz_jGjOEQH3x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44PVoBkiMRmA"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict**"
      ],
      "metadata": {
        "id": "2oYxYhcERQ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict function for several texts in a file\n",
        "def predict(test_data: pd.DataFrame, output_path: str) -> pd.DataFrame:\n",
        "  return 0\n",
        "\n",
        "# predict function for only one text\n",
        "def predict(test_text: pd.DataFrame):\n",
        "  return 0"
      ],
      "metadata": {
        "id": "3yzKEl8oRWpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}